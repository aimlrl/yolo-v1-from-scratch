{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VGG16\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Conv2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_boxes(image_size,grids_size,aspect_ratios):\n",
    "\n",
    "    image_width, image_height, _ = image_size\n",
    "\n",
    "    grid_width = image_width//grids_size[0]\n",
    "    grid_height = image_height//grids_size[1]\n",
    "\n",
    "    grid_center_x_start = grid_width//2\n",
    "    grid_center_x_end = (grids_size[0] - 0.5)*grid_width \n",
    "\n",
    "    grid_center_x = np.linspace(grid_center_x_start,grid_center_x_end,grids_size[0])\n",
    "\n",
    "    grid_center_y_start = grid_height//2\n",
    "    grid_center_y_end = (grids_size[1] - 0.5)*grid_height\n",
    "\n",
    "    grid_center_y = np.linspace(grid_center_y_start,grid_center_y_end,grids_size[1])\n",
    "\n",
    "    grid_center_x_mesh, grid_center_y_mesh = np.meshgrid(grid_center_x,grid_center_y)\n",
    "\n",
    "    grid_center_x_mesh = np.expand_dims(grid_center_x_mesh,-1)\n",
    "    grid_center_y_mesh = np.expand_dims(grid_center_y_mesh,-1)\n",
    "\n",
    "    anchor_boxes_no = len(aspect_ratios)\n",
    "\n",
    "    anchor_boxes_tensor = np.zeros((grids_size[0],grids_size[1],anchor_boxes_no,4))\n",
    "\n",
    "    anchor_boxes_tensor[...,0] = np.tile(grid_center_x_mesh,(1,1,anchor_boxes_no))\n",
    "    anchor_boxes_tensor[...,1] = np.tile(grid_center_y_mesh,(1,1,anchor_boxes_no))\n",
    "\n",
    "    anchor_box_width_height = list()\n",
    "\n",
    "    for aspect_ratio in aspect_ratios:\n",
    "\n",
    "        anchor_box_width_height.append((grid_width*np.sqrt(aspect_ratio),\n",
    "                                        grid_height/np.sqrt(aspect_ratio)))\n",
    "        \n",
    "    anchor_box_width_height = np.array(anchor_box_width_height)\n",
    "\n",
    "    anchor_boxes_tensor[...,2] = anchor_box_width_height[:,0]\n",
    "    anchor_boxes_tensor[...,3] = anchor_box_width_height[:,1]\n",
    "\n",
    "    return anchor_boxes_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid2minmax(anchor_boxes_centroid_tensor):\n",
    "\n",
    "    anchor_boxes_minmax_tensor = np.copy(anchor_boxes_centroid_tensor)\n",
    "\n",
    "    anchor_boxes_minmax_tensor[...,0] = anchor_boxes_minmax_tensor[...,0] - (anchor_boxes_minmax_tensor[...,2]//2)\n",
    "    anchor_boxes_minmax_tensor[...,1] = anchor_boxes_minmax_tensor[...,1] - (anchor_boxes_minmax_tensor[...,3]//2)\n",
    "    anchor_boxes_minmax_tensor[...,2] = anchor_boxes_minmax_tensor[...,0] + (anchor_boxes_minmax_tensor[...,2]//2)\n",
    "    anchor_boxes_minmax_tensor[...,3] = anchor_boxes_minmax_tensor[...,1] + (anchor_boxes_minmax_tensor[...,3]//2)\n",
    "\n",
    "    return anchor_boxes_minmax_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_IoU(anchor_boxes_tensor,image_gt_bbox_coords):\n",
    "\n",
    "    IoU_tensor = np.zeros((len(image_gt_bbox_coords),anchor_boxes_tensor.shape[0],anchor_boxes_tensor.shape[1],anchor_boxes_tensor.shape[2]))\n",
    "    anchor_boxes_minmax_tensor = centroid2minmax(anchor_boxes_tensor)\n",
    "\n",
    "    gt_bboxes_mask = np.zeros((len(image_gt_bbox_coords),anchor_boxes_tensor.shape[0],anchor_boxes_tensor.shape[1],anchor_boxes_tensor.shape[2]))\n",
    "\n",
    "    for i in range(len(image_gt_bbox_coords)):\n",
    "\n",
    "        centroid_x_condition = (anchor_boxes_minmax_tensor[:,:,0,0]<(image_gt_bbox_coords[i,0]+image_gt_bbox_coords[i,2]//2)) & (anchor_boxes_minmax_tensor[:,:,0,2]>(image_gt_bbox_coords[i,0]+image_gt_bbox_coords[i,2]//2))\n",
    "        centroid_y_condition = (anchor_boxes_minmax_tensor[:,:,0,1]<(image_gt_bbox_coords[i,1]+image_gt_bbox_coords[i,3]//2)) & (anchor_boxes_minmax_tensor[:,:,0,3]>(image_gt_bbox_coords[i,1]+image_gt_bbox_coords[i,3]//2))\n",
    "\n",
    "        idxes = np.argwhere((centroid_x_condition & centroid_y_condition))\n",
    "\n",
    "        gt_bboxes_mask[i,idxes,:] = 1.0\n",
    "\n",
    "        for j in range(anchor_boxes_tensor.shape[2]):\n",
    "\n",
    "            xmin_intersection = np.maximum(image_gt_bbox_coords[i][0],anchor_boxes_minmax_tensor[:,:,j,0])\n",
    "            ymin_intersection = np.maximum(image_gt_bbox_coords[i][1],anchor_boxes_minmax_tensor[:,:,j,1])\n",
    "\n",
    "            xmax_intersection = np.minimum(image_gt_bbox_coords[i][0]+image_gt_bbox_coords[i][2],anchor_boxes_minmax_tensor[:,:,j,2])\n",
    "            ymax_intersection = np.minimum(image_gt_bbox_coords[i][1]+image_gt_bbox_coords[i][3],anchor_boxes_minmax_tensor[:,:,j,3])\n",
    "\n",
    "            intersection_width = np.maximum(0,(xmax_intersection - xmin_intersection))\n",
    "            intersection_height = np.maximum(0,(ymax_intersection - ymin_intersection))\n",
    "\n",
    "            intersection_area = intersection_width * intersection_height\n",
    "\n",
    "            image_gt_bbox_area = image_gt_bbox_coords[i][2] * image_gt_bbox_coords[i][3]\n",
    "            anchor_boxes_width = (anchor_boxes_minmax_tensor[:,:,j,2] - anchor_boxes_minmax_tensor[:,:,j,0])\n",
    "            anchor_boxes_height = (anchor_boxes_minmax_tensor[:,:,j,3] - anchor_boxes_minmax_tensor[:,:,j,1])\n",
    "\n",
    "            union_area = ((anchor_boxes_width * anchor_boxes_height) + image_gt_bbox_area) - intersection_area\n",
    "\n",
    "            IoU_tensor[i,:,:,j] = intersection_area/union_area\n",
    "\n",
    "    return gt_bboxes_mask, IoU_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_bbox_coords(image_size, image_gt_bbox_coords, gt_bboxes_mask, anchor_boxes_tensor):\n",
    "\n",
    "    image_width, image_height, _ = image_size\n",
    "    normalized_image_gt_bbox_coords = np.zeros_like(anchor_boxes_tensor)\n",
    "    \n",
    "    for i in range(len(image_gt_bbox_coords)):\n",
    "\n",
    "        idx = np.argwhere((gt_bboxes_mask[i,:,:,0] == 1.0) | (gt_bboxes_mask[i,:,:,1] == 1.0))\n",
    "        normalized_image_gt_bbox_coords[idx,:,0] = (image_gt_bbox_coords[i][0] + (image_gt_bbox_coords[i][2]//2))/(image_gt_bbox_coords[i][0] + image_gt_bbox_coords[i][2])\n",
    "        normalized_image_gt_bbox_coords[idx,:,1] = (image_gt_bbox_coords[i][1] + (image_gt_bbox_coords[i][3]//2))/(image_gt_bbox_coords[i][1] + image_gt_bbox_coords[i][3])\n",
    "        normalized_image_gt_bbox_coords[idx,:,2] = image_gt_bbox_coords[i][2]//image_width\n",
    "        normalized_image_gt_bbox_coords[idx,:,3] = image_gt_bbox_coords[i][3]//image_height\n",
    "\n",
    "    return normalized_image_gt_bbox_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_labels_tensor(normalized_image_gt_bbox_coords, IoU_tensor, gt_bboxes_mask, image_cls_labels, num_classes):\n",
    "\n",
    "    cls_probabilities_tensor = np.zeros((normalized_image_gt_bbox_coords.shape[0],normalized_image_gt_bbox_coords.shape[1],num_classes))\n",
    "\n",
    "    for i in range(gt_bboxes_mask.shape[0]):\n",
    "\n",
    "        idx = np.argwhere((gt_bboxes_mask[i,:,:,0] == 1.0) | (gt_bboxes_mask[i,:,:,1] == 1.0))\n",
    "        cls_probabilities_tensor[idx,:] = np.eye(num_classes,num_classes)[image_cls_labels[i]]\n",
    "\n",
    "    gt_labels_tensor = np.copy(normalized_image_gt_bbox_coords)\n",
    "    #The below three statements to compute the confidence scores assumes that\n",
    "    #there is single object present in a Grid Cell which may not be the case.\n",
    "    confidence_scores = IoU_tensor * gt_bboxes_mask\n",
    "    final_confidence_scores = np.sum(confidence_scores,axis=0)\n",
    "    final_confidence_scores = np.expand_dims(final_confidence_scores,-1)\n",
    "    gt_labels_tensor = np.concatenate((gt_labels_tensor,final_confidence_scores),axis=3)\n",
    "    gt_labels_tensor = gt_labels_tensor.reshape(gt_labels_tensor.shape[0],gt_labels_tensor.shape[1],gt_labels_tensor.shape[2]*gt_labels_tensor.shape[3])\n",
    "\n",
    "    gt_labels_tensor = np.concatenate((gt_labels_tensor,cls_probabilities_tensor),axis=2)\n",
    "    \n",
    "    return gt_labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_cnn():\n",
    "\n",
    "    vgg16 = VGG16(include_top=False,input_shape=(640,480,3),weights=\"imagenet\",pooling=None)\n",
    "    vgg16.trainable = False\n",
    "    input_to_vgg16 = vgg16.layers[0].input\n",
    "    vgg16_output = Conv2D(filters=90,kernel_size=(14,9))(vgg16.layers[-1].output)\n",
    "\n",
    "    return Model(inputs=[input_to_vgg16],outputs=[vgg16_output])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
