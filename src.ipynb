{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type:ignore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Conv2D\n",
    "from keras.models import Model\n",
    "import pathlib\n",
    "import os\n",
    "from xml.etree import ElementTree as ET\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_boxes(image_size,grids_size,aspect_ratios):\n",
    "\n",
    "    image_width, image_height, _ = image_size\n",
    "\n",
    "    grid_width = image_width//grids_size[0]\n",
    "    grid_height = image_height//grids_size[1]\n",
    "\n",
    "    grid_center_x_start = grid_width//2\n",
    "    grid_center_x_end = int((grids_size[0] - 0.5)*grid_width) \n",
    "\n",
    "    grid_center_x = np.linspace(grid_center_x_start,grid_center_x_end,grids_size[0])\n",
    "\n",
    "    grid_center_y_start = grid_height//2\n",
    "    grid_center_y_end = int((grids_size[1] - 0.5)*grid_height)\n",
    "\n",
    "    grid_center_y = np.linspace(grid_center_y_start,grid_center_y_end,grids_size[1])\n",
    "\n",
    "    grid_center_x_mesh, grid_center_y_mesh = np.meshgrid(grid_center_x,grid_center_y)\n",
    "\n",
    "    grid_center_x_mesh = np.expand_dims(grid_center_x_mesh,-1)\n",
    "    grid_center_y_mesh = np.expand_dims(grid_center_y_mesh,-1)\n",
    "\n",
    "    anchor_boxes_no = len(aspect_ratios)\n",
    "\n",
    "    anchor_boxes_tensor = np.zeros((grids_size[0],grids_size[1],anchor_boxes_no,4))\n",
    "\n",
    "    anchor_boxes_tensor[...,0] = np.tile(grid_center_x_mesh,(1,1,anchor_boxes_no))\n",
    "    anchor_boxes_tensor[...,1] = np.tile(grid_center_y_mesh,(1,1,anchor_boxes_no))\n",
    "\n",
    "    anchor_box_width_height = list()\n",
    "\n",
    "    for aspect_ratio in aspect_ratios:\n",
    "\n",
    "        anchor_box_width_height.append((158*np.sqrt(aspect_ratio),\n",
    "                                        173/np.sqrt(aspect_ratio)))\n",
    "        \n",
    "    anchor_box_width_height = np.array(anchor_box_width_height)\n",
    "\n",
    "    anchor_boxes_tensor[...,2] = anchor_box_width_height[:,0]\n",
    "    anchor_boxes_tensor[...,3] = anchor_box_width_height[:,1]\n",
    "\n",
    "    return anchor_boxes_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid2minmax(anchor_boxes_centroid_tensor):\n",
    "\n",
    "    anchor_boxes_minmax_tensor = np.copy(anchor_boxes_centroid_tensor)\n",
    "\n",
    "    anchor_boxes_minmax_tensor[...,0] = anchor_boxes_minmax_tensor[...,0] - (anchor_boxes_minmax_tensor[...,2]//2)\n",
    "    anchor_boxes_minmax_tensor[...,1] = anchor_boxes_minmax_tensor[...,1] - (anchor_boxes_minmax_tensor[...,3]//2)\n",
    "    anchor_boxes_minmax_tensor[...,2] = anchor_boxes_minmax_tensor[...,0] + (anchor_boxes_minmax_tensor[...,2]//2)\n",
    "    anchor_boxes_minmax_tensor[...,3] = anchor_boxes_minmax_tensor[...,1] + (anchor_boxes_minmax_tensor[...,3]//2)\n",
    "\n",
    "    return anchor_boxes_minmax_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_IoU(anchor_boxes_minmax_tensor,image_gt_bbox_coords):\n",
    "\n",
    "    image_gt_bbox_centroid_coords = np.array(image_gt_bbox_coords)\n",
    "    image_gt_bbox_centroid_coords[:,0] = image_gt_bbox_centroid_coords[:,0] +\\\n",
    "                                         (image_gt_bbox_centroid_coords[:,2] - image_gt_bbox_centroid_coords[:,0])//2\n",
    "    image_gt_bbox_centroid_coords[:,1] = image_gt_bbox_centroid_coords[:,1] +\\\n",
    "                                         (image_gt_bbox_centroid_coords[:,3] - image_gt_bbox_centroid_coords[:,1])//2\n",
    "    image_gt_bbox_centroid_coords[:,2] = (image_gt_bbox_centroid_coords[:,2] - image_gt_bbox_centroid_coords[:,0])\n",
    "    image_gt_bbox_centroid_coords[:,3] = (image_gt_bbox_centroid_coords[:,3] - image_gt_bbox_centroid_coords[:,1]) \n",
    "    \n",
    "    IoU_tensor = np.zeros((len(image_gt_bbox_coords),anchor_boxes_minmax_tensor.shape[0],anchor_boxes_minmax_tensor.shape[1],\n",
    "                    anchor_boxes_minmax_tensor.shape[2]))\n",
    "    bbox_present_idxes = [[]]*len(image_gt_bbox_coords) \n",
    "    IoU_thresh = 0.25\n",
    "\n",
    "    for i in range(len(image_gt_bbox_coords)):\n",
    "\n",
    "        for j in range(anchor_boxes_minmax_tensor.shape[2]):\n",
    "            \"\"\"\n",
    "            centroid_x_condition_anchor_boxes = ((image_gt_bbox_centroid_coords[i,0] > anchor_boxes_minmax_tensor[:,:,j,0]) & \n",
    "                                               (image_gt_bbox_centroid_coords[i,0] < anchor_boxes_minmax_tensor[:,:,j,2]))\n",
    "            centroid_y_condition_anchor_boxes = ((image_gt_bbox_centroid_coords[i,1] > anchor_boxes_minmax_tensor[:,:,j,1]) & \n",
    "                                               (image_gt_bbox_centroid_coords[i,1] < anchor_boxes_minmax_tensor[:,:,j,3]))\n",
    "            grid_cells_idxes = np.argwhere(centroid_x_condition_anchor_boxes & centroid_y_condition_anchor_boxes)\n",
    "            bbox_present_idxes[i].append(grid_cells_idxes)\n",
    "            \"\"\"\n",
    "\n",
    "            xmin_intersection = np.maximum(image_gt_bbox_coords[i][0],anchor_boxes_minmax_tensor[:,:,j,0])\n",
    "            ymin_intersection = np.maximum(image_gt_bbox_coords[i][1],anchor_boxes_minmax_tensor[:,:,j,1])\n",
    "\n",
    "            xmax_intersection = np.minimum(image_gt_bbox_coords[i][2],anchor_boxes_minmax_tensor[:,:,j,2])\n",
    "            ymax_intersection = np.minimum(image_gt_bbox_coords[i][3],anchor_boxes_minmax_tensor[:,:,j,3])\n",
    "\n",
    "            intersection_width = np.maximum(0,(xmax_intersection - xmin_intersection))\n",
    "            intersection_height = np.maximum(0,(ymax_intersection - ymin_intersection))\n",
    "\n",
    "            intersection_area = intersection_width * intersection_height\n",
    "\n",
    "            image_gt_bbox_area = image_gt_bbox_centroid_coords[i,2] * image_gt_bbox_centroid_coords[i,3]\n",
    "            anchor_boxes_width = (anchor_boxes_minmax_tensor[:,:,j,2] - anchor_boxes_minmax_tensor[:,:,j,0])\n",
    "            anchor_boxes_height = (anchor_boxes_minmax_tensor[:,:,j,3] - anchor_boxes_minmax_tensor[:,:,j,1])\n",
    "\n",
    "            union_area = ((anchor_boxes_width * anchor_boxes_height) + image_gt_bbox_area) - intersection_area\n",
    "\n",
    "            IoU_tensor[i,:,:,j] = intersection_area/union_area\n",
    "            bbox_present_idxes[i].append(np.argwhere(IoU_tensor[i,:,:,j] > 0))\n",
    "            #print(\"IoU_tensor for IoU of {}th Anchor Box with the GT Bounding Box of Object # {} is {}\".format(j+1,i+1, IoU_tensor[i,:,:,j]))\n",
    "\n",
    "    IoU_tensor_reduced = np.max(IoU_tensor,axis=0)\n",
    "    anchor_boxes_gt_mask = np.float64(IoU_tensor_reduced > IoU_thresh)\n",
    "\n",
    "    return image_gt_bbox_centroid_coords, anchor_boxes_gt_mask, bbox_present_idxes, IoU_tensor_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_bbox_coords(image_size,amchor_boxes_gt_mask,bbox_present_idxes,image_gt_bbox_centroid_coords,anchor_boxes_minmax_tensor):\n",
    "\n",
    "    image_width, image_height, _ = image_size\n",
    "    normalized_image_gt_bbox_coords = np.zeros_like(anchor_boxes_minmax_tensor)\n",
    "\n",
    "    for i in range(len(image_gt_bbox_centroid_coords)):\n",
    "    \n",
    "        for j in range(anchor_boxes_minmax_tensor.shape[2]):\n",
    "\n",
    "            idx = bbox_present_idxes[i][j]\n",
    "\n",
    "            normalized_image_gt_bbox_coords[idx[:,0],idx[:,1],j,0] = image_gt_bbox_centroid_coords[i][0]/anchor_boxes_minmax_tensor[idx[:,0],idx[:,1],j,2]\n",
    "            normalized_image_gt_bbox_coords[idx[:,0],idx[:,1],j,1] = image_gt_bbox_centroid_coords[i][1]/anchor_boxes_minmax_tensor[idx[:,0],idx[:,1],j,3]\n",
    "            normalized_image_gt_bbox_coords[idx[:,0],idx[:,1],j,2] = image_gt_bbox_centroid_coords[i][2]/image_width\n",
    "            normalized_image_gt_bbox_coords[idx[:,0],idx[:,1],j,3] = image_gt_bbox_centroid_coords[i][3]/image_height\n",
    "\n",
    "    return normalized_image_gt_bbox_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_labels_tensor(normalized_image_gt_bbox_coords, IoU_tensor, bbox_present_idxes, image_cls_labels, num_classes):\n",
    "\n",
    "    cls_probabilities_tensor = np.zeros((normalized_image_gt_bbox_coords.shape[0],normalized_image_gt_bbox_coords.shape[1],num_classes))\n",
    "\n",
    "    for i in range(len(bbox_present_idxes)):\n",
    "        idx_0 = bbox_present_idxes[i][0]\n",
    "        idx_1 = bbox_present_idxes[i][1]\n",
    "        cls_probabilities_tensor[idx_0[:,0],idx_0[:,1],:] = np.eye(num_classes,num_classes)[image_cls_labels[i]]\n",
    "        cls_probabilities_tensor[idx_1[:,0],idx_1[:,1],:] = np.eye(num_classes,num_classes)[image_cls_labels[i]]\n",
    "\n",
    "    gt_labels_tensor = np.copy(normalized_image_gt_bbox_coords)\n",
    "    confidence_scores = np.expand_dims(IoU_tensor,-1)\n",
    "    gt_labels_tensor = np.concatenate((gt_labels_tensor,confidence_scores),axis=3)\n",
    "    gt_labels_tensor = gt_labels_tensor.reshape(gt_labels_tensor.shape[0],gt_labels_tensor.shape[1],gt_labels_tensor.shape[2]*gt_labels_tensor.shape[3])\n",
    "    gt_labels_tensor = np.concatenate((gt_labels_tensor,cls_probabilities_tensor),axis=2)\n",
    "    \n",
    "    return gt_labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection_cnn():\n",
    "\n",
    "    vgg16 = VGG16(include_top=False,input_shape=(480,640,3),weights=\"imagenet\",pooling=None)\n",
    "    vgg16.trainable = False\n",
    "    input_to_vgg16 = vgg16.input\n",
    "    vgg16_output = Conv2D(filters=30,kernel_size=(9,14),activation=\"relu\")(vgg16.layers[-1].output)\n",
    "\n",
    "    return Model(inputs=[input_to_vgg16],outputs=[vgg16_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov1_cnn = object_detection_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov1_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_df(imgs_base_path,annotations_base_path):\n",
    "\n",
    "    img_complete_paths = list()\n",
    "    img_class_labels = list()\n",
    "    img_gt_bbox_coords = list()\n",
    "\n",
    "    for single_img_complete_path in pathlib.Path(imgs_base_path).glob(\"*\"):\n",
    "\n",
    "        img_path = str(single_img_complete_path)\n",
    "        img_label_path = os.path.join(annotations_base_path,str(single_img_complete_path).split(\"/\")[-1].split(\".\")[0]+\".xml\")\n",
    "\n",
    "        class_gt_labels_list = list()\n",
    "        gt_bbox_coords_list = list()\n",
    "\n",
    "        tree = ET.parse(img_label_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for member in root.findall(\"object\"):\n",
    "            \n",
    "            class_gt_labels_list.append(member.find(\"name\").text)\n",
    "            xmin = float(member.find(\"bndbox/xmin\").text)\n",
    "            ymin = float(member.find(\"bndbox/ymin\").text)\n",
    "            xmax = float(member.find(\"bndbox/xmax\").text)\n",
    "            ymax = float(member.find(\"bndbox/ymax\").text)\n",
    "            \n",
    "            #bbox_width = xmax - xmin\n",
    "            #bbox_height = ymax - ymin\n",
    "            \n",
    "            gt_bbox_coords_list.append([xmin,ymin,xmax,ymax])\n",
    "\n",
    "        img_complete_paths.append(str(single_img_complete_path))\n",
    "        img_class_labels.append(class_gt_labels_list)\n",
    "        img_gt_bbox_coords.append(gt_bbox_coords_list)\n",
    "\n",
    "    return pd.DataFrame(data={\"img_path\":img_complete_paths,\n",
    "                              \"img_gt_class_labels\":img_class_labels,\n",
    "                              \"img_gt_bbox_coords\":img_gt_bbox_coords})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df = train_test_df(\"VOCdevkit/VOC2012/JPEGImages\",\"VOCdevkit/VOC2012/Annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "unique_labels = set()\n",
    "\n",
    "for img_labels in data_df.iloc[:,1]:\n",
    "    unique_labels = unique_labels.union(set(img_labels))\n",
    "\n",
    "unique_labels = list(unique_labels)\n",
    "#unique_labels.insert(0,\"background\")\n",
    "\n",
    "labels2idx = dict(zip(unique_labels,range(len(unique_labels))))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def labels2idx_mapping(img_labels):\n",
    "\n",
    "    return list(map(lambda x: labels2idx[x],img_labels))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df.iloc[:,1] = data_df.iloc[:,1].apply(labels2idx_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data_df[\"img_gt_class_labels\"] = data_df[\"img_gt_class_labels\"].apply(json.dumps)\n",
    "data_df[\"img_gt_bbox_coords\"] = data_df[\"img_gt_bbox_coords\"].apply(json.dumps)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "training_data = data_df.iloc[0:15000,:]\n",
    "cv_data = data_df.iloc[15000:,]\n",
    "\n",
    "training_data.to_csv(\"./training_data.csv\",index=False)\n",
    "cv_data.to_csv(\"./cv_data.csv\",index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"training_data.csv\")\n",
    "training_data[\"img_gt_class_labels\"] = training_data[\"img_gt_class_labels\"].apply(ast.literal_eval)\n",
    "training_data[\"img_gt_bbox_coords\"] = training_data[\"img_gt_bbox_coords\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imread(training_data.iloc[0,0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(plt.imread(training_data.iloc[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_boxes_tensor = anchor_boxes((640,480,3),(7,7),(1/2,2))\n",
    "anchor_boxes_minmax_tensor = centroid2minmax(anchor_boxes_tensor)\n",
    "image_gt_bbox_cenroid_coords, anchor_boxes_gt_mask, bbox_present_idxes,iou_tensor = compute_IoU(anchor_boxes_minmax_tensor,training_data.iloc[0,2])\n",
    "normalized_gt_bbox_coords = normalize_bbox_coords((640,480,3),anchor_boxes_gt_mask,bbox_present_idxes,image_gt_bbox_cenroid_coords,\n",
    "                                                  anchor_boxes_minmax_tensor)\n",
    "gt_labels_tensor = create_gt_labels_tensor(normalized_gt_bbox_coords,iou_tensor,bbox_present_idxes,training_data.iloc[0,1],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_data_generator(df,mb_size):\n",
    "\n",
    "    for i in range(df.shape[0]//mb_size):\n",
    "\n",
    "        X_train_mb = list()\n",
    "        Y_train_mb = list()\n",
    "        GT_mask_train_mb = list()\n",
    "\n",
    "        for j in range(0,mb_size):\n",
    "\n",
    "            df_mb = df.iloc[(i*mb_size)+j]\n",
    "            img_path = df_mb[\"img_path\"]\n",
    "\n",
    "            X_train_mb.append(cv2.resize(plt.imread(img_path),(640,480)))\n",
    "\n",
    "            gt_bboxes_mask, iou_tensor = compute_IoU(anchor_boxes_tensor,df_mb[\"img_gt_bbox_coords\"])\n",
    "            normalized_img_gt_bbox_coords = normalize_bbox_coords((640,480,3),df_mb[\"img_gt_bbox_coords\"],\n",
    "                                                                  gt_bboxes_mask,anchor_boxes_tensor)\n",
    "            Y_train, final_gt_bboxes_mask = create_gt_labels_tensor(normalized_img_gt_bbox_coords,iou_tensor,\n",
    "                                                                    gt_bboxes_mask,df_mb[\"img_gt_class_labels\"],20)\n",
    "            \n",
    "            Y_train_mb.append(Y_train)\n",
    "            GT_mask_train_mb.append(final_gt_bboxes_mask)\n",
    "            \n",
    "        yield np.array(X_train_mb), np.array(Y_train_mb), np.array(GT_mask_train_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_fn(Y_true_mb,Y_pred_mb,GT_mask_train_mb,lambda_coord,lambda_noobj):\n",
    "\n",
    "    squared_error = (Y_true_mb - Y_pred_mb)**2\n",
    "\n",
    "    \"\"\"\n",
    "    squared_error_with_mask = GT_mask_train_mb * squared_error\n",
    "    squared_error_with_neg_mask = (1.0 - GT_mask_train_mb) * squared_error\n",
    "    \"\"\"\n",
    "\n",
    "    cx_cy_squared_error_tensor = np.concatenate((GT_mask_train_mb*squared_error[:,:,:,0:2],\n",
    "                                                 GT_mask_train_mb*squared_error[:,:,:,5:7]),axis=0)\n",
    "    \n",
    "    sqrt_squared_error = (np.sqrt(Y_true_mb) - np.sqrt(Y_pred_mb))**2\n",
    "\n",
    "    #sqrt_squared_error_with_mask = GT_mask_train_mb * sqrt_squared_error\n",
    "    \n",
    "    wh_sqrt_squared_error_tensor = np.concatenate((GT_mask_train_mb*sqrt_squared_error[:,:,:,2:4],\n",
    "                                                   GT_mask_train_mb*sqrt_squared_error[:,:,:,7:9]),axis=0)\n",
    "    \n",
    "    loss_fn_first_term = lambda_coord*np.sum(cx_cy_squared_error_tensor)\n",
    "    loss_fn_second_term = lambda_coord*np.sum(wh_sqrt_squared_error_tensor)\n",
    "\n",
    "    confidence_score_error_tensor = GT_mask_train_mb*np.concatenate((np.expand_dims(squared_error[:,:,:,4],-1),\n",
    "                                                                     np.expand_dims(squared_error[:,:,:,9],-1)),\n",
    "                                                                     axis=3)\n",
    "    \n",
    "    loss_fn_third_term = np.sum(confidence_score_error_tensor)\n",
    "\n",
    "    confidence_score_noobj_error_tensor = (1.0 - GT_mask_train_mb)*np.concatenate((np.expand_dims(squared_error[:,:,:,4],-1),\n",
    "                                                                                   np.expand_dims(squared_error[:,:,:,9],-1)),\n",
    "                                                                                   axis=3)\n",
    "\n",
    "    loss_fn_forth_term = lambda_noobj*np.sum(confidence_score_noobj_error_tensor)\n",
    "\n",
    "    loss_fn_fifth_term = np.sum(GT_mask_train_mb[:,:,:,0]*np.sum(squared_error[:,:,:,10:],axis=3))\n",
    "\n",
    "    overall_loss_fn = loss_fn_first_term + loss_fn_second_term + loss_fn_third_term +\\\n",
    "                        loss_fn_forth_term + loss_fn_fifth_term\n",
    "    \n",
    "    return overall_loss_fn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
