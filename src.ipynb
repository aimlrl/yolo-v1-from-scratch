{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Conv2D\n",
    "from keras.models import Model\n",
    "import pathlib\n",
    "import os\n",
    "from xml.etree import ElementTree as ET\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_boxes(image_size,grids_size,aspect_ratios):\n",
    "\n",
    "    image_width, image_height, _ = image_size\n",
    "\n",
    "    grid_width = image_width//grids_size[0]\n",
    "    grid_height = image_height//grids_size[1]\n",
    "\n",
    "    grid_center_x_start = grid_width//2\n",
    "    grid_center_x_end = (grids_size[0] - 0.5)*grid_width \n",
    "\n",
    "    grid_center_x = np.linspace(grid_center_x_start,grid_center_x_end,grids_size[0])\n",
    "\n",
    "    grid_center_y_start = grid_height//2\n",
    "    grid_center_y_end = (grids_size[1] - 0.5)*grid_height\n",
    "\n",
    "    grid_center_y = np.linspace(grid_center_y_start,grid_center_y_end,grids_size[1])\n",
    "\n",
    "    grid_center_x_mesh, grid_center_y_mesh = np.meshgrid(grid_center_x,grid_center_y)\n",
    "\n",
    "    grid_center_x_mesh = np.expand_dims(grid_center_x_mesh,-1)\n",
    "    grid_center_y_mesh = np.expand_dims(grid_center_y_mesh,-1)\n",
    "\n",
    "    anchor_boxes_no = len(aspect_ratios)\n",
    "\n",
    "    anchor_boxes_tensor = np.zeros((grids_size[0],grids_size[1],anchor_boxes_no,4))\n",
    "\n",
    "    anchor_boxes_tensor[...,0] = np.tile(grid_center_x_mesh,(1,1,anchor_boxes_no))\n",
    "    anchor_boxes_tensor[...,1] = np.tile(grid_center_y_mesh,(1,1,anchor_boxes_no))\n",
    "\n",
    "    anchor_box_width_height = list()\n",
    "\n",
    "    for aspect_ratio in aspect_ratios:\n",
    "\n",
    "        anchor_box_width_height.append((grid_width*np.sqrt(aspect_ratio),\n",
    "                                        grid_height/np.sqrt(aspect_ratio)))\n",
    "        \n",
    "    anchor_box_width_height = np.array(anchor_box_width_height)\n",
    "\n",
    "    anchor_boxes_tensor[...,2] = anchor_box_width_height[:,0]\n",
    "    anchor_boxes_tensor[...,3] = anchor_box_width_height[:,1]\n",
    "\n",
    "    return anchor_boxes_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid2minmax(anchor_boxes_centroid_tensor):\n",
    "\n",
    "    anchor_boxes_minmax_tensor = np.copy(anchor_boxes_centroid_tensor)\n",
    "\n",
    "    anchor_boxes_minmax_tensor[...,0] = anchor_boxes_minmax_tensor[...,0] - (anchor_boxes_minmax_tensor[...,2]//2)\n",
    "    anchor_boxes_minmax_tensor[...,1] = anchor_boxes_minmax_tensor[...,1] - (anchor_boxes_minmax_tensor[...,3]//2)\n",
    "    anchor_boxes_minmax_tensor[...,2] = anchor_boxes_minmax_tensor[...,0] + (anchor_boxes_minmax_tensor[...,2]//2)\n",
    "    anchor_boxes_minmax_tensor[...,3] = anchor_boxes_minmax_tensor[...,1] + (anchor_boxes_minmax_tensor[...,3]//2)\n",
    "\n",
    "    return anchor_boxes_minmax_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_IoU(anchor_boxes_tensor,image_gt_bbox_coords):\n",
    "\n",
    "    image_gt_bbox_coords = np.array(image_gt_bbox_coords)\n",
    "    IoU_tensor = np.zeros((len(image_gt_bbox_coords),anchor_boxes_tensor.shape[0],anchor_boxes_tensor.shape[1],anchor_boxes_tensor.shape[2]))\n",
    "    anchor_boxes_minmax_tensor = centroid2minmax(anchor_boxes_tensor)\n",
    "\n",
    "    gt_bboxes_mask = np.zeros((len(image_gt_bbox_coords),anchor_boxes_tensor.shape[0],anchor_boxes_tensor.shape[1],anchor_boxes_tensor.shape[2]))\n",
    "\n",
    "    for i in range(len(image_gt_bbox_coords)):\n",
    "\n",
    "        centroid_x_condition = (anchor_boxes_minmax_tensor[:,:,0,0]<(image_gt_bbox_coords[i,0]+image_gt_bbox_coords[i,2]//2)) & (anchor_boxes_minmax_tensor[:,:,0,2]>(image_gt_bbox_coords[i,0]+image_gt_bbox_coords[i,2]//2))\n",
    "        centroid_y_condition = (anchor_boxes_minmax_tensor[:,:,0,1]<(image_gt_bbox_coords[i,1]+image_gt_bbox_coords[i,3]//2)) & (anchor_boxes_minmax_tensor[:,:,0,3]>(image_gt_bbox_coords[i,1]+image_gt_bbox_coords[i,3]//2))\n",
    "\n",
    "        idxes = np.argwhere((centroid_x_condition & centroid_y_condition))\n",
    "        gt_bboxes_mask[i,idxes,:] = 1.0\n",
    "\n",
    "        for j in range(anchor_boxes_tensor.shape[2]):\n",
    "\n",
    "            xmin_intersection = np.maximum(image_gt_bbox_coords[i][0],anchor_boxes_minmax_tensor[:,:,j,0])\n",
    "            ymin_intersection = np.maximum(image_gt_bbox_coords[i][1],anchor_boxes_minmax_tensor[:,:,j,1])\n",
    "\n",
    "            xmax_intersection = np.minimum(image_gt_bbox_coords[i][0]+image_gt_bbox_coords[i][2],anchor_boxes_minmax_tensor[:,:,j,2])\n",
    "            ymax_intersection = np.minimum(image_gt_bbox_coords[i][1]+image_gt_bbox_coords[i][3],anchor_boxes_minmax_tensor[:,:,j,3])\n",
    "\n",
    "            intersection_width = np.maximum(0,(xmax_intersection - xmin_intersection))\n",
    "            intersection_height = np.maximum(0,(ymax_intersection - ymin_intersection))\n",
    "\n",
    "            intersection_area = intersection_width * intersection_height\n",
    "\n",
    "            image_gt_bbox_area = image_gt_bbox_coords[i][2] * image_gt_bbox_coords[i][3]\n",
    "            anchor_boxes_width = (anchor_boxes_minmax_tensor[:,:,j,2] - anchor_boxes_minmax_tensor[:,:,j,0])\n",
    "            anchor_boxes_height = (anchor_boxes_minmax_tensor[:,:,j,3] - anchor_boxes_minmax_tensor[:,:,j,1])\n",
    "\n",
    "            union_area = ((anchor_boxes_width * anchor_boxes_height) + image_gt_bbox_area) - intersection_area\n",
    "\n",
    "            IoU_tensor[i,:,:,j] = intersection_area/union_area\n",
    "\n",
    "    return gt_bboxes_mask, IoU_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_bbox_coords(image_size, image_gt_bbox_coords, gt_bboxes_mask, anchor_boxes_tensor):\n",
    "\n",
    "    image_width, image_height, _ = image_size\n",
    "    normalized_image_gt_bbox_coords = np.zeros_like(anchor_boxes_tensor)\n",
    "    \n",
    "    for i in range(len(image_gt_bbox_coords)):\n",
    "\n",
    "        idx = np.argwhere((gt_bboxes_mask[i,:,:,0] == 1.0) | (gt_bboxes_mask[i,:,:,1] == 1.0))\n",
    "        normalized_image_gt_bbox_coords[idx[:,0],idx[:,1],:,0] = (image_gt_bbox_coords[i][0] + (image_gt_bbox_coords[i][2]//2))/(image_gt_bbox_coords[i][0] + image_gt_bbox_coords[i][2])\n",
    "        normalized_image_gt_bbox_coords[idx[:,0],idx[:,1],:,1] = (image_gt_bbox_coords[i][1] + (image_gt_bbox_coords[i][3]//2))/(image_gt_bbox_coords[i][1] + image_gt_bbox_coords[i][3])\n",
    "        normalized_image_gt_bbox_coords[idx[:,0],idx[:,1],:,2] = image_gt_bbox_coords[i][2]//image_width\n",
    "        normalized_image_gt_bbox_coords[idx[:,0],idx[:,1],:,3] = image_gt_bbox_coords[i][3]//image_height\n",
    "\n",
    "    return normalized_image_gt_bbox_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_labels_tensor(normalized_image_gt_bbox_coords, IoU_tensor, gt_bboxes_mask, image_cls_labels, num_classes):\n",
    "\n",
    "    cls_probabilities_tensor = np.zeros((normalized_image_gt_bbox_coords.shape[0],normalized_image_gt_bbox_coords.shape[1],num_classes))\n",
    "\n",
    "    for i in range(gt_bboxes_mask.shape[0]):\n",
    "\n",
    "        idx = np.argwhere((gt_bboxes_mask[i,:,:,0] == 1.0) | (gt_bboxes_mask[i,:,:,1] == 1.0))\n",
    "        cls_probabilities_tensor[idx,:] = np.eye(num_classes,num_classes)[image_cls_labels[i]]\n",
    "\n",
    "    gt_labels_tensor = np.copy(normalized_image_gt_bbox_coords)\n",
    "    #The below three statements to compute the confidence scores assumes that\n",
    "    #there is single object present in a Grid Cell which may not be the case.\n",
    "    confidence_scores = IoU_tensor * gt_bboxes_mask\n",
    "    final_confidence_scores = np.sum(confidence_scores,axis=0)\n",
    "    final_confidence_scores = np.expand_dims(final_confidence_scores,-1)\n",
    "    gt_labels_tensor = np.concatenate((gt_labels_tensor,final_confidence_scores),axis=3)\n",
    "    gt_labels_tensor = gt_labels_tensor.reshape(gt_labels_tensor.shape[0],gt_labels_tensor.shape[1],gt_labels_tensor.shape[2]*gt_labels_tensor.shape[3])\n",
    "\n",
    "    gt_labels_tensor = np.concatenate((gt_labels_tensor,cls_probabilities_tensor),axis=2)\n",
    "    \n",
    "    return gt_labels_tensor, np.sum(gt_bboxes_mask,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection_cnn():\n",
    "\n",
    "    vgg16 = VGG16(include_top=False,input_shape=(480,640,3),weights=\"imagenet\",pooling=None)\n",
    "    vgg16.trainable = False\n",
    "    input_to_vgg16 = vgg16.input\n",
    "    vgg16_output = Conv2D(filters=30,kernel_size=(9,14),activation=\"relu\")(vgg16.layers[-1].output)\n",
    "\n",
    "    return Model(inputs=[input_to_vgg16],outputs=[vgg16_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov1_cnn = object_detection_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov1_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_df(imgs_base_path,annotations_base_path):\n",
    "\n",
    "    img_complete_paths = list()\n",
    "    img_class_labels = list()\n",
    "    img_gt_bbox_coords = list()\n",
    "\n",
    "    for single_img_complete_path in pathlib.Path(imgs_base_path).glob(\"*\"):\n",
    "\n",
    "        img_path = str(single_img_complete_path)\n",
    "        img_label_path = os.path.join(annotations_base_path,str(single_img_complete_path).split(\"/\")[-1].split(\".\")[0]+\".xml\")\n",
    "\n",
    "        class_gt_labels_list = list()\n",
    "        gt_bbox_coords_list = list()\n",
    "\n",
    "        tree = ET.parse(img_label_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for member in root.findall(\"object\"):\n",
    "            \"\"\"\n",
    "            for child in member:\n",
    "\n",
    "                if child.tag == \"name\":\n",
    "                    class_gt_labels_list.append(child.text)\n",
    "\n",
    "                if child.tag == \"bndbox\":\n",
    "                    xmin = float(child[0].text)\n",
    "                    ymin = float(child[1].text)\n",
    "                    xmax = float(child[2].text)\n",
    "                    ymax = float(child[3].text)\n",
    "            \"\"\"\n",
    "            class_gt_labels_list.append(member.find(\"name\").text)\n",
    "            xmin = float(member.find(\"bndbox/xmin\").text)\n",
    "            ymin = float(member.find(\"bndbox/ymin\").text)\n",
    "            xmax = float(member.find(\"bndbox/xmax\").text)\n",
    "            ymax = float(member.find(\"bndbox/ymax\").text)\n",
    "            \n",
    "            bbox_width = xmax - xmin\n",
    "            bbox_height = ymax - ymin\n",
    "            \n",
    "\n",
    "            gt_bbox_coords_list.append([xmin,ymin,bbox_width,bbox_height])\n",
    "\n",
    "        img_complete_paths.append(str(single_img_complete_path))\n",
    "        img_class_labels.append(class_gt_labels_list)\n",
    "        img_gt_bbox_coords.append(gt_bbox_coords_list)\n",
    "\n",
    "    return pd.DataFrame(data={\"img_path\":img_complete_paths,\n",
    "                              \"img_gt_class_labels\":img_class_labels,\n",
    "                              \"img_gt_bbox_coords\":img_gt_bbox_coords})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df = train_test_df(\"VOCdevkit/VOC2012/JPEGImages\",\"VOCdevkit/VOC2012/Annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "unique_labels = set()\n",
    "\n",
    "for img_labels in data_df.iloc[:,1]:\n",
    "    unique_labels = unique_labels.union(set(img_labels))\n",
    "\n",
    "unique_labels = list(unique_labels)\n",
    "#unique_labels.insert(0,\"background\")\n",
    "\n",
    "labels2idx = dict(zip(unique_labels,range(len(unique_labels))))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def labels2idx_mapping(img_labels):\n",
    "\n",
    "    return list(map(lambda x: labels2idx[x],img_labels))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df.iloc[:,1] = data_df.iloc[:,1].apply(labels2idx_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data_df[\"img_gt_class_labels\"] = data_df[\"img_gt_class_labels\"].apply(json.dumps)\n",
    "data_df[\"img_gt_bbox_coords\"] = data_df[\"img_gt_bbox_coords\"].apply(json.dumps)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "training_data = data_df.iloc[0:15000,:]\n",
    "cv_data = data_df.iloc[15000:,]\n",
    "\n",
    "training_data.to_csv(\"./training_data.csv\",index=False)\n",
    "cv_data.to_csv(\"./cv_data.csv\",index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"training_data.csv\")\n",
    "training_data[\"img_gt_class_labels\"] = training_data[\"img_gt_class_labels\"].apply(ast.literal_eval)\n",
    "training_data[\"img_gt_bbox_coords\"] = training_data[\"img_gt_bbox_coords\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imread(training_data.iloc[0,0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(plt.imread(training_data.iloc[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_boxes_tensor = anchor_boxes((640,480,3),(7,7),(1/2,2))\n",
    "anchor_boxes_minmax_tensor = centroid2minmax(anchor_boxes_tensor)\n",
    "\"\"\"\n",
    "gt_bboxes_mask,iou_tensor = compute_IoU(anchor_boxes_tensor,training_data.iloc[0,2])\n",
    "#normalized_gt_bbox_coords = normalize_bbox_coords((640,480,3),training_data.iloc[0,2],gt_bboxes_mask,anchor_boxes_tensor)\n",
    "#gt_labels_tensor = create_gt_labels_tensor(normalized_gt_bbox_coords,iou_tensor,gt_bboxes_mask,training_data.iloc[0,1],\n",
    "                                           20)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_data_generator(df,mb_size):\n",
    "\n",
    "    for i in range(df.shape[0]//mb_size):\n",
    "\n",
    "        X_train_mb = list()\n",
    "        Y_train_mb = list()\n",
    "        GT_mask_train_mb = list()\n",
    "\n",
    "        for j in range(0,mb_size):\n",
    "\n",
    "            df_mb = df.iloc[(i*mb_size)+j]\n",
    "            img_path = df_mb[\"img_path\"]\n",
    "\n",
    "            X_train_mb.append(cv2.resize(plt.imread(img_path),(640,480)))\n",
    "\n",
    "            gt_bboxes_mask, iou_tensor = compute_IoU(anchor_boxes_tensor,df_mb[\"img_gt_bbox_coords\"])\n",
    "            normalized_img_gt_bbox_coords = normalize_bbox_coords((640,480,3),df_mb[\"img_gt_bbox_coords\"],\n",
    "                                                                  gt_bboxes_mask,anchor_boxes_tensor)\n",
    "            Y_train, final_gt_bboxes_mask = create_gt_labels_tensor(normalized_img_gt_bbox_coords,iou_tensor,\n",
    "                                                                    gt_bboxes_mask,df_mb[\"img_gt_class_labels\"],20)\n",
    "            \n",
    "            Y_train_mb.append(Y_train)\n",
    "            GT_mask_train_mb.append(final_gt_bboxes_mask)\n",
    "            \n",
    "        yield np.array(X_train_mb), np.array(Y_train_mb), np.array(GT_mask_train_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_fn(Y_true_mb,Y_pred_mb,GT_mask_train_mb,lambda_coord,lambda_noobj):\n",
    "\n",
    "    squared_error = (Y_true_mb - Y_pred_mb)**2\n",
    "\n",
    "    \"\"\"\n",
    "    squared_error_with_mask = GT_mask_train_mb * squared_error\n",
    "    squared_error_with_neg_mask = (1.0 - GT_mask_train_mb) * squared_error\n",
    "    \"\"\"\n",
    "\n",
    "    cx_cy_squared_error_tensor = np.concatenate((GT_mask_train_mb*squared_error[:,:,:,0:2],\n",
    "                                                 GT_mask_train_mb*squared_error[:,:,:,5:7]),axis=0)\n",
    "    \n",
    "    sqrt_squared_error = (np.sqrt(Y_true_mb) - np.sqrt(Y_pred_mb))**2\n",
    "\n",
    "    #sqrt_squared_error_with_mask = GT_mask_train_mb * sqrt_squared_error\n",
    "    \n",
    "    wh_sqrt_squared_error_tensor = np.concatenate((GT_mask_train_mb*sqrt_squared_error[:,:,:,2:4],\n",
    "                                                   GT_mask_train_mb*sqrt_squared_error[:,:,:,7:9]),axis=0)\n",
    "    \n",
    "    loss_fn_first_term = lambda_coord*np.sum(cx_cy_squared_error_tensor)\n",
    "    loss_fn_second_term = lambda_coord*np.sum(wh_sqrt_squared_error_tensor)\n",
    "\n",
    "    confidence_score_error_tensor = GT_mask_train_mb*np.concatenate((np.expand_dims(squared_error[:,:,:,4],-1),\n",
    "                                                                     np.expand_dims(squared_error[:,:,:,9],-1)),\n",
    "                                                                     axis=3)\n",
    "    \n",
    "    loss_fn_third_term = np.sum(confidence_score_error_tensor)\n",
    "\n",
    "    confidence_score_noobj_error_tensor = (1.0 - GT_mask_train_mb)*np.concatenate((np.expand_dims(squared_error[:,:,:,4],-1),\n",
    "                                                                                   np.expand_dims(squared_error[:,:,:,9],-1)),\n",
    "                                                                                   axis=3)\n",
    "\n",
    "    loss_fn_forth_term = lambda_noobj*np.sum(confidence_score_noobj_error_tensor)\n",
    "\n",
    "    loss_fn_fifth_term = np.sum(GT_mask_train_mb[:,:,:,0]*np.sum(squared_error[:,:,:,10:],axis=3))\n",
    "\n",
    "    overall_loss_fn = loss_fn_first_term + loss_fn_second_term + loss_fn_third_term +\\\n",
    "                        loss_fn_forth_term + loss_fn_fifth_term\n",
    "    \n",
    "    return overall_loss_fn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
